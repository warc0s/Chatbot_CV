# ğŸ¤– ChatBot CV: RAG vs Context Size

![Banner](https://github.com/warc0s/Chatbot_CV/blob/dev/extra/banner.png?raw=true)

## ğŸ“‘ Ãndice
- [DescripciÃ³n General](#descripciÃ³n-general)
- [Â¿QuÃ© es RAG y TamaÃ±o de Contexto?](#quÃ©-es-rag-y-tamaÃ±o-de-contexto)
- [TecnologÃ­as Implementadas](#tecnologÃ­as-implementadas)
- [Sistema Inteligente de ClasificaciÃ³n](#sistema-inteligente-de-clasificaciÃ³n)
- [OptimizaciÃ³n de Costos y Rendimiento](#optimizaciÃ³n-de-costos-y-rendimiento)
- [Frameworks y Herramientas](#frameworks-y-herramientas)
- [Disclaimers Importantes](#disclaimers-importantes)
- [Licencia](#licencia)

## ğŸ“‹ DescripciÃ³n General
Este proyecto implementa y evalÃºa dos tecnologÃ­as avanzadas de chatbot utilizando la informaciÃ³n de mi currÃ­culum profesional. Ofrece un anÃ¡lisis comparativo entre dos enfoques de inteligencia artificial: RAG (GeneraciÃ³n Aumentada por RecuperaciÃ³n) y modelos con gran ventana de contexto.

## ğŸ§  Â¿QuÃ© es RAG y TamaÃ±o de Contexto?
- **RAG (GeneraciÃ³n Aumentada por RecuperaciÃ³n)** ğŸ“š: Es una tÃ©cnica que permite a un modelo de IA buscar informaciÃ³n relevante en documentos externos antes de generar una respuesta. Funciona como si el modelo tuviera un asistente que primero busca la informaciÃ³n necesaria y luego la utiliza para responder.

- **TamaÃ±o de Contexto** ğŸ“: Representa cuÃ¡nta informaciÃ³n puede "recordar" un modelo de IA durante una conversaciÃ³n. Un modelo con mayor tamaÃ±o de contexto puede mantener en memoria mÃ¡s informaciÃ³n sin necesidad de buscarla externamente.

## ğŸ’» TecnologÃ­as Implementadas

### Enfoque LLM + RAG
- **Modelo**: Llama 3.3 (70B parÃ¡metros) ğŸ¦™
- **Framework**: LlamaIndex para implementaciÃ³n RAG âš¡
- **Funcionamiento**: El sistema primero busca en mi CV la informaciÃ³n relevante a la pregunta y luego genera una respuesta basada en esos datos especÃ­ficos.
- **Ventajas**: Respuestas precisas y altamente contextualizadas, incluso para informaciÃ³n detallada o poco comÃºn.

### Enfoque de Gran Ventana de Contexto
- **Modelo**: Gemini Flash ğŸ’
- **IntegraciÃ³n**: ConexiÃ³n mediante liteLLM ğŸ”„
- **Capacidad**: Memoria de 1 millÃ³n de tokens (equivalente a cientos de pÃ¡ginas de texto)
- **Ventajas**: Conversaciones fluidas y rÃ¡pidas sin necesidad de buscar externamente, ya que mantiene todo el CV en memoria.

## ğŸ” Sistema Inteligente de ClasificaciÃ³n
Para optimizar tanto el rendimiento como los costes, se implementa una arquitectura que incluye:

- **Clasificador** ğŸ§©: Modelo BERT en espaÃ±ol adaptado para clasificar la intenciÃ³n de las preguntas
- **CategorÃ­as de ClasificaciÃ³n**:
  1. **Preguntas simples** âœ…: Como "Â¿QuÃ© estudiÃ³ Marcos?" â†’ Utiliza Gemini Flash Lite (econÃ³mico)
  2. **Preguntas complejas** ğŸ”„: Como "Â¿Se ajusta el perfil de Marcos a estos requisitos de trabajo?" â†’ Utiliza Gemini Flash (mÃ¡s potente)
  3. **Preguntas fuera de tema** âŒ: Como "Â¿QuÃ© tiempo hace hoy?" â†’ Bloqueadas (evitando uso inadecuado)

## âš™ï¸ OptimizaciÃ³n de Costos y Rendimiento
El sistema dirige inteligentemente cada consulta al modelo mÃ¡s adecuado segÃºn su complejidad, garantizando el mejor rendimiento posible mientras controla los costes y previene usos indebidos del sistema.

## ğŸ› ï¸ Frameworks y Herramientas
- **liteLLM**: Utilizado para gestionar la conexiÃ³n con los modelos de Gemini de forma eficiente y estandarizada
- **LlamaIndex**: Framework clave para implementar la funcionalidad RAG, permitiendo indexaciÃ³n, bÃºsqueda y generaciÃ³n aumentada
- **BERT**: Modelo de clasificaciÃ³n para determinar el tipo de consulta del usuario

## âš ï¸ Disclaimers Importantes
- **Sistema de clasificaciÃ³n BERT**: Actualmente, el clasificador BERT para detecciÃ³n de intenciones SOLO estÃ¡ implementado para la versiÃ³n de Gemini Flash.
- **Estado del enfoque LLM+RAG**: La implementaciÃ³n con Llama 3.3 y RAG todavÃ­a NO estÃ¡ desarrollada. Este enfoque se implementarÃ¡ en futuras actualizaciones del proyecto utilizando el framework LlamaIndex para la parte de recuperaciÃ³n y generaciÃ³n.
- **Fase actual**: El proyecto se encuentra en fase de desarrollo y evaluaciÃ³n, por lo que algunas funcionalidades pueden estar sujetas a cambios significativos.

## ğŸ“œ Licencia
Licenciado bajo Apache License 2.0. Consulte el archivo LICENSE para mÃ¡s detalles.
